{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq_ALhRCbGar"
   },
   "source": [
    "```\n",
    "// Copyright 2020 Twitter, Inc.\n",
    "// SPDX-License-Identifier: Apache-2.0\n",
    "```\n",
    "\n",
    "# Finetune Text Classification Models\n",
    "\n",
    "Take an existing BERT model (with or without TPP pre-training) and fine-tune it on an Text Classification dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxcm3TN4tTXM"
   },
   "source": [
    "## Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoEOULN2bSF6"
   },
   "outputs": [],
   "source": [
    "%pip install transformers==3.5.1 datasets==1.1.2 torch==1.4.0 seqeval==1.2.2 gensim==3.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_hHGnVvfkbb"
   },
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZz4UdIufPi2"
   },
   "outputs": [],
   "source": [
    "HOMEDIR = \"../\"\n",
    "DATADIR = f\"{HOMEDIR}/data\"\n",
    "MODELDIR = f\"{HOMEDIR}/models\"\n",
    "pre_trained_model_path = \"bert-base-multilingual-uncased\"\n",
    "langs = \"en\"  # \"en\" # \"**\"\n",
    "\n",
    "task_type = \"sentiment\"\n",
    "LABEL_KEY = \"label\"\n",
    "TEXT_KEY = \"text\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjnn9-jNsfIx"
   },
   "source": [
    "## Setup Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mfn7vXjrbGay"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.debugger import set_trace\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizerFast,\n",
    "    EvalPrediction,\n",
    "    Pipeline,\n",
    "    RobertaTokenizerFast,\n",
    "    TokenClassificationPipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.tokenization_utils_base import (\n",
    "    BatchEncoding,\n",
    "    PaddingStrategy,\n",
    "    PreTrainedTokenizerBase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQTmO44cbGaz"
   },
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        else:\n",
    "            return super(NumpyArrayEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7NgqbxlbGaz"
   },
   "outputs": [],
   "source": [
    "URL_REGEX = re.compile(r\"^http[s]?://[^ ]+\")\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if ord(text[0]) == 65039:\n",
    "        text = text[1:]\n",
    "    if text == chr(65039):\n",
    "        return \"\"\n",
    "    text = text.replace(\"\\n\", \"[LF]\")\n",
    "    return URL_REGEX.sub(\"[URL]\", text)\n",
    "\n",
    "\n",
    "def read_classification_data(file_list, label_key=LABEL_KEY, return_dict=False):\n",
    "    all_text = []\n",
    "    all_label = []\n",
    "    all_data = []\n",
    "\n",
    "    for file_path in tqdm(file_list):\n",
    "        with open(file_path) as fp:\n",
    "            for line in fp:\n",
    "                if not line:\n",
    "                    continue\n",
    "                line = json.loads(line)\n",
    "                if return_dict:\n",
    "                    all_data.append(line)\n",
    "                    continue\n",
    "                text = clean_text(line[TEXT_KEY])\n",
    "                label = line[label_key]\n",
    "                if label == \"neutral\":\n",
    "                    continue\n",
    "                all_text.append(text)\n",
    "                all_label.append(label)\n",
    "    if return_dict:\n",
    "        return all_data\n",
    "    return all_text, all_label\n",
    "\n",
    "\n",
    "label2id = {\"NOT\": 0, \"OFF\": 1}\n",
    "\n",
    "\n",
    "if task_type == \"sentiment\":\n",
    "    label2id = {\"negative\": 0, \"positive\": 1}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvoL3DNsbGa1"
   },
   "outputs": [],
   "source": [
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths, tokenizer):\n",
    "        self.file_paths = file_paths\n",
    "        self.tokenizer = tokenizer\n",
    "        self._setup()\n",
    "\n",
    "    def _setup(self):\n",
    "        all_text, all_label = read_classification_data(self.file_paths)\n",
    "        self.data = []\n",
    "        num_errors = 0\n",
    "        all_encodings = self.tokenizer(all_text, max_length=max_length, truncation=True)\n",
    "        for i, label in tqdm(enumerate(all_label)):\n",
    "            label = label2id[label]\n",
    "            encodings = {k: v[i] for k, v in all_encodings.items()}\n",
    "            self.data.append((encodings, label))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encodings, label = self.data[idx]\n",
    "        item = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        item[\"label\"] = torch.tensor(label)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5Ft9ui5bGa1"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    result = classification_report(p.label_ids, preds)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_preds(df_data, classification_pipeline, text_key=TEXT_KEY):\n",
    "    # For now we assume binary classification tasks\n",
    "    all_preds = []\n",
    "    batch_size = 64\n",
    "    for i in trange(0, len(df_data[text_key].values) + batch_size, batch_size):\n",
    "        batch = df_data[text_key].values[i : i + batch_size].tolist()\n",
    "        if batch:\n",
    "            preds = classification_pipeline(batch)\n",
    "            preds = [\n",
    "                (\n",
    "                    max(pred, key=lambda x: x[\"score\"])[\"label\"],\n",
    "                    pred[0][\"score\"],\n",
    "                    pred[1][\"score\"],\n",
    "                )\n",
    "                for pred in preds\n",
    "            ]\n",
    "            all_preds.extend(preds)\n",
    "    return all_preds\n",
    "\n",
    "\n",
    "def get_report(df_preds, label_key=LABEL_KEY):\n",
    "    if df_preds.shape[0] == 0:\n",
    "        print(f\"No data in df_preds\")\n",
    "        return None\n",
    "    y_true = df_preds[label_key]\n",
    "    y_pred = df_preds[\"pred\"]\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred))\n",
    "    report = {\n",
    "        \"classification_report\": classification_report(\n",
    "            y_true=y_true, y_pred=y_pred, output_dict=True\n",
    "        )\n",
    "    }\n",
    "    probas_pred = df_preds[\"1_score\"]\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        y_true=y_true, probas_pred=probas_pred, pos_label=id2label[1]\n",
    "    )\n",
    "    pr_auc = auc(recall, precision)\n",
    "    pr_curve = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"thresholds\": thresholds,\n",
    "        \"pr_auc\": pr_auc,\n",
    "    }\n",
    "    report[\"pr_curve\"] = pr_curve\n",
    "    print(f\"PRAUC: {pr_auc}\")\n",
    "    return report\n",
    "\n",
    "\n",
    "def run_eval(file_paths, classification_pipeline):\n",
    "    df_data = read_classification_data(file_paths, return_dict=True)\n",
    "    df_data = pd.DataFrame(df_data)\n",
    "\n",
    "    all_preds = get_preds(df_data, classification_pipeline)\n",
    "    df_preds = pd.DataFrame(all_preds, columns=[\"pred\", \"0_score\", \"1_score\"])\n",
    "    df_preds = pd.concat([df_data.drop(TEXT_KEY, 1), df_preds], axis=1)\n",
    "\n",
    "    report = get_report(df_preds, label_key=LABEL_KEY)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8flhGO3vbGa3"
   },
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaSHiYPHbGa3"
   },
   "outputs": [],
   "source": [
    "# model_dir = Path(f\"{HOMEDIR}/en_sentiment_model/\").expanduser()\n",
    "model_dir = pre_trained_model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    str(model_dir), max_len=512, truncation=True, padding=True, use_fast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIrKtwMubGa4",
    "outputId": "26ff8308-87e4-4047-f41e-8cbcfbc332b2"
   },
   "outputs": [],
   "source": [
    "data_dir = Path(f\"{DATADIR}/SentimentData/\").expanduser()\n",
    "train_data_path = list(data_dir.glob(f\"./{langs}/training.json\"))\n",
    "test_data_path = list(data_dir.glob(f\"./{langs}/testing.json\"))\n",
    "\n",
    "\n",
    "train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1C0o5WyZbGa4",
    "outputId": "c2c1900f-2605-4194-f4d2-11e5dc209cf2"
   },
   "outputs": [],
   "source": [
    "train_dataset = ClassificationDataset(train_data_path, tokenizer)\n",
    "val_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQwQW3ANbGa5",
    "outputId": "0ed07f24-8431-488a-c36a-6a12e8bdcc07"
   },
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cz3I5LOcbGa5"
   },
   "outputs": [],
   "source": [
    "model_prefix = \"multi\" if langs == \"**\" else langs\n",
    "finetuned_model_dir = str(\n",
    "    Path(f\"{MODELDIR}/{model_prefix}_{task_type}_model\").expanduser()\n",
    ")\n",
    "logging_dir = str(Path(f\"{MODELDIR}/{model_prefix}_{task_type}_logs\").expanduser())\n",
    "\n",
    "\n",
    "eval_every_steps = -1  # 1 # -1 for eval at end\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(finetuned_model_dir),  # output directory\n",
    "    num_train_epochs=3,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=str(logging_dir),  # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=100,\n",
    "    save_steps=500 if eval_every_steps < 1 else eval_every_steps,\n",
    "    save_total_limit=2 if eval_every_steps < 1 else None,\n",
    "    max_steps=-1 if eval_every_steps < 1 else 5,\n",
    "    label_names=[id2label[i] for i in range(len(id2label))],\n",
    ")\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        str(model_dir), num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
    "        args=training_args,  # training arguments, defined above\n",
    "        train_dataset=train_dataset,  # training dataset\n",
    "        # eval_dataset=val_dataset,             # evaluation dataset\n",
    "        # data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(finetuned_model_dir)\n",
    "    tokenizer.save_pretrained(finetuned_model_dir)\n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE7lu7bDbGa6",
    "outputId": "a63a8aaa-a881-48ca-abd8-13e4e700d941"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model, trainer = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHV9SyyWbGa7"
   },
   "source": [
    "## Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFFLaV7_bGa7"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import auc, classification_report, precision_recall_curve\n",
    "from tqdm import trange\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Pipeline,\n",
    "    TokenClassificationPipeline,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wF7nte8sbGa8"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "# del classification_pipeline\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poJ31DDUbGa8"
   },
   "outputs": [],
   "source": [
    "task_type = \"sentiment\"\n",
    "\n",
    "finetuned_model_dir = str(\n",
    "    Path(f\"{MODELDIR}/{model_prefix}_{task_type}_model\").expanduser()\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(finetuned_model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    str(model_dir), max_len=512, truncation=True, padding=True, use_fast=True\n",
    ")\n",
    "\n",
    "\n",
    "def _parse_and_tokenize(self, inputs, padding=True, add_special_tokens=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Parse arguments and tokenize\n",
    "    \"\"\"\n",
    "    # Parse arguments\n",
    "    inputs = self.tokenizer(\n",
    "        inputs,\n",
    "        add_special_tokens=add_special_tokens,\n",
    "        return_tensors=self.framework,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcFcXRsDbGa8"
   },
   "outputs": [],
   "source": [
    "classification_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True,\n",
    "    device=0,\n",
    ")\n",
    "classification_pipeline.__class__.__bases__[0]._parse_and_tokenize = _parse_and_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-GX7kovbGa9",
    "outputId": "f82b1686-f61d-4f9a-9340-f42944a80abd"
   },
   "outputs": [],
   "source": [
    "langs = \"**\"  # \"en\" # \"**\"\n",
    "\n",
    "data_dir = Path(f\"{DATADIR}/SentimentData/\").expanduser()\n",
    "train_data_path = list(data_dir.glob(f\"./{langs}/training.json\"))\n",
    "test_data_path = list(data_dir.glob(f\"./{langs}/testing.json\"))\n",
    "\n",
    "test_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZH2b-7tVbGa9",
    "outputId": "1f319af9-edd7-4cf9-8089-8a9f8cc9bd53"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "reports = {}\n",
    "for test_path in test_data_path:\n",
    "    lang = test_path.parts[-2]\n",
    "    subset = test_path.parts[-3]\n",
    "    print(lang, subset, test_path.name)\n",
    "    report = run_eval([test_path], classification_pipeline)\n",
    "    df_report = pd.DataFrame(report[\"classification_report\"]).T\n",
    "    reports[(lang, subset)] = df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUiJ-kwHbGa9",
    "outputId": "4f50454a-e831-4415-99d9-536a69dd2fa1"
   },
   "outputs": [],
   "source": [
    "df_report = pd.concat(reports)\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khrJs42UbGa-"
   },
   "outputs": [],
   "source": [
    "df_report.to_csv(Path(finetuned_model_dir) / \"test_eval_report.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGXRq18hbGa-",
    "outputId": "443e6f9a-e372-451d-f45a-f6a3c0189b92"
   },
   "outputs": [],
   "source": [
    "df_report[df_report.index.isin([\"macro avg\"], level=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzS_FQQQbGa-",
    "outputId": "f414f035-96fd-4ddf-f41a-df852d7edc87"
   },
   "outputs": [],
   "source": [
    "df_report = pd.read_csv(\n",
    "    Path(finetuned_model_dir) / \"test_eval_report.txt\", sep=\"\\t\", index_col=[0, 1, 2]\n",
    ")\n",
    "df_report[df_report.index.isin([\"macro avg\"], level=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQ9iVU2BbGa_",
    "outputId": "475dc02f-e262-428c-d443-cc5d28d834e6"
   },
   "outputs": [],
   "source": [
    "if Path(f\"{str(finetuned_model_dir)}/test_eval_report.txt\").expanduser().exists():\n",
    "    df_report = pd.read_csv(\n",
    "        f\"{str(finetuned_model_dir)}/test_eval_report.txt\", sep=\"\\t\", index_col=[0, 1, 2]\n",
    "    )\n",
    "df_report[df_report.index.isin([\"macro avg\"], level=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHe3dx_ebGa_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1d-NwLNbGa_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Finetune_TextClassification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mldash_entity": {
   "created_at_millis": 1612210248003,
   "hash": "dbd26a54ada9a7a87ba8c229ec0bb9450c4d9611",
   "inferred_pdp_safe": true,
   "is_vfs_dir": false,
   "marked_pdp_safe": false,
   "owner": "smishra",
   "shared_to_everyone": false,
   "shared_to_ldap_groups": [],
   "shared_to_ldap_users": [],
   "size": 9665,
   "tags": [],
   "uuid": "1356334202552139778",
   "vfs_path": "/user/smishra/notebooks/NLPLib/Finetune_OffenseEval.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
